{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDELYgR_AcMJ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfXszoT7AUoI"
      },
      "outputs": [],
      "source": [
        "# Load packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix, auc, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import metrics\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_zSHLuhAqPJ"
      },
      "outputs": [],
      "source": [
        "# Get data\n",
        "vdem_2022_repl = pd.read_csv(\"https://raw.githubusercontent.com/vdeminstitute/part/main/create-data/output/part-v12.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy_WZHnHBGwN"
      },
      "outputs": [],
      "source": [
        "# Create training data set (1970 to 2020)\n",
        "train_data = vdem_2022_repl[vdem_2022_repl['year']<2021]\n",
        "\n",
        "# Create test data set (2014 to 2020) <-- this follows the baseline paper approach (not good practice!)\n",
        "test_data_pre = vdem_2022_repl[vdem_2022_repl['year']>2013]\n",
        "test_data = test_data_pre[test_data_pre['year']<2021]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1uFuKJRBt_t"
      },
      "outputs": [],
      "source": [
        "# Select features and target variables for train and data sets\n",
        "\n",
        "X_train = train_data.drop(columns = [\"gwcode\", \"year\", \"country_name\", \"country_text_id\", \"country_id\",\n",
        "             \"v2x_regime\", \"v2x_regime_amb\", \"any_neg_change\", \"lagged_v2x_regime_asCharacter\", \"lagged_v2x_regime_asFactor\", \"any_neg_change_2yr\"], axis=1)\n",
        "             \n",
        "# Step above drops several identifier variables not needed for modeling (same approach as baseline)\n",
        "y_train = train_data.any_neg_change_2yr.values # Target variable\n",
        "\n",
        "# For test_data\n",
        "X_test = test_data.drop(columns = [\"gwcode\", \"year\", \"country_name\", \"country_text_id\", \"country_id\",\n",
        "             \"v2x_regime\", \"v2x_regime_amb\", \"any_neg_change\",\"lagged_v2x_regime_asCharacter\", \"lagged_v2x_regime_asFactor\", \"any_neg_change_2yr\"], axis=1)\n",
        "y_test = test_data.any_neg_change_2yr.values # Target variable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOFkDOnFBmuc"
      },
      "source": [
        "## Model 0: Plain Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44njowN6CKU_"
      },
      "outputs": [],
      "source": [
        "# Build model 0\n",
        "scaler = StandardScaler()\n",
        "lr0 = LogisticRegression(solver='lbfgs', max_iter=400)\n",
        "model0 = Pipeline([('standardize', scaler),\n",
        "                   ('log_reg',lr0)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RbvtggzCOFh",
        "outputId": "f8a9503e-ffd4-40ff-9d36-f7fe41bb2532"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardize', StandardScaler()),\n",
              "                ('log_reg', LogisticRegression(max_iter=400))])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Fit model 0\n",
        "model0.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOjjw3eJCUvI"
      },
      "source": [
        "Evaluating training score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOheuYW_CTzF",
        "outputId": "1f350ce2-6f65-428a-aeda-0007ff88198d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[7669   29]\n",
            " [ 190  133]]\n",
            "Training Accuracy: 97.2697 %\n",
            "Training AUC: 96.3032 %\n",
            "Training Precision: 82.0988 %\n",
            "Training Recall: 41.1765 %\n"
          ]
        }
      ],
      "source": [
        "y_train_hat0 = model0.predict(X_train)\n",
        "y_train_hat_probs0 = model0.predict_proba(X_train)[:,1]\n",
        "\n",
        "train_accuracy0 = accuracy_score(y_train, y_train_hat0)*100\n",
        "train_auc_roc0 = roc_auc_score(y_train, y_train_hat_probs0)*100\n",
        "\n",
        "train_precision0 = precision_score(y_train, y_train_hat0)*100\n",
        "train_recall0 = recall_score(y_train, y_train_hat0)*100\n",
        "\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_train, y_train_hat0))\n",
        "\n",
        "print('Training Accuracy: %.4f %%' % train_accuracy0)\n",
        "print('Training AUC: %.4f %%' % train_auc_roc0)\n",
        "print('Training Precision: %.4f %%' % train_precision0)\n",
        "print('Training Recall: %.4f %%' % train_recall0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi1usmc-PZRG"
      },
      "source": [
        "Evaluating testing score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL2ZV7YLPdca",
        "outputId": "86c0ce71-f3ca-4527-f4e8-509a4d4cdb28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[1108    7]\n",
            " [  42   26]]\n",
            "Test Accuracy: 95.8580 %\n",
            "Test AUC: 94.8444 %\n",
            "Test Precision: 78.7879 %\n",
            "Test Recall: 38.2353 %\n"
          ]
        }
      ],
      "source": [
        "y_test_hat0 = model0.predict(X_test)\n",
        "y_test_hat_probs0 = model0.predict_proba(X_test)[:,1]\n",
        "\n",
        "test_accuracy0 = accuracy_score(y_test, y_test_hat0)*100\n",
        "test_auc_roc0 = roc_auc_score(y_test, y_test_hat_probs0)*100\n",
        "\n",
        "test_precision0 = precision_score(y_test, y_test_hat0)*100\n",
        "test_recall0 = recall_score(y_test, y_test_hat0)*100\n",
        "\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_test, y_test_hat0))\n",
        "\n",
        "print('Test Accuracy: %.4f %%' % test_accuracy0)\n",
        "print('Test AUC: %.4f %%' % test_auc_roc0)\n",
        "print('Test Precision: %.4f %%' % test_precision0)\n",
        "print('Test Recall: %.4f %%' % test_recall0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cax5Er-uP2gd",
        "outputId": "492f4872-eb09-44ee-99d0-d219339a65fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0   0.963478  0.993722  0.978366      1115\n",
            "         1.0   0.787879  0.382353  0.514851        68\n",
            "\n",
            "    accuracy                       0.958580      1183\n",
            "   macro avg   0.875679  0.688037  0.746609      1183\n",
            "weighted avg   0.953385  0.958580  0.951723      1183\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print classification report\n",
        "print(classification_report(y_test, y_test_hat0, digits=6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPn2FDeVDMEv"
      },
      "source": [
        "## Model 1: Logistic Regression with Elastic Net Regularization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwZS-Rx1DQ0m"
      },
      "outputs": [],
      "source": [
        "# Build model\n",
        "scaler = StandardScaler()\n",
        "lr1 = LogisticRegression(solver='saga',penalty='elasticnet', l1_ratio=0.5, max_iter=6000)\n",
        "model1 = Pipeline([('standardize', scaler),\n",
        "                   ('log_reg',lr1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9MXMvF5DcRu",
        "outputId": "b6f5b4be-97ed-4ac7-8859-21d12047296c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardize', StandardScaler()),\n",
              "                ('log_reg',\n",
              "                 LogisticRegression(l1_ratio=0.5, max_iter=6000,\n",
              "                                    penalty='elasticnet', solver='saga'))])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Fit model\n",
        "model1.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Twct2uDQdYsc"
      },
      "outputs": [],
      "source": [
        "# Predict y values for test data\n",
        "logit_pred=model1.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pREzsQxiDhvq"
      },
      "source": [
        "Evaluate training score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqkm6WBQDjzc",
        "outputId": "8cbba35d-837c-4f1c-b5e0-2ad297b8f611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[7669   29]\n",
            " [ 203  120]]\n",
            "Training Accuracy: 97.1076 %\n",
            "Training AUC: 95.9706 %\n",
            "Training Precision: 80.5369 %\n",
            "Training Recall: 37.1517 %\n"
          ]
        }
      ],
      "source": [
        "y_train_hat1 = model1.predict(X_train)\n",
        "y_train_hat_probs1 = model1.predict_proba(X_train)[:,1]\n",
        "\n",
        "train_accuracy1 = accuracy_score(y_train, y_train_hat1)*100\n",
        "train_auc_roc1 = roc_auc_score(y_train, y_train_hat_probs1)*100\n",
        "train_precision1 = precision_score(y_train, y_train_hat1)*100\n",
        "train_recall1 = recall_score(y_train, y_train_hat1)*100\n",
        "\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_train, y_train_hat1))\n",
        "\n",
        "print('Training Accuracy: %.4f %%' % train_accuracy1)\n",
        "print('Training AUC: %.4f %%' % train_auc_roc1)\n",
        "print('Training Precision: %.4f %%' % train_precision1)\n",
        "print('Training Recall: %.4f %%' % train_recall1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzHsZT4mSZjL"
      },
      "source": [
        "Evaluating testing score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsFO3Ho3SeLN",
        "outputId": "7e39b844-2b33-4d1f-91c1-2dec9a3c590a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[1108    7]\n",
            " [  44   24]]\n",
            "Testing Accuracy: 95.6889 %\n",
            "Testing AUC: 94.3656 %\n",
            "Testing Precision: 77.4194 %\n",
            "Testing Recall: 35.2941 %\n"
          ]
        }
      ],
      "source": [
        "y_test_hat1 = model1.predict(X_test)\n",
        "y_test_hat_probs1 = model1.predict_proba(X_test)[:,1]\n",
        "\n",
        "test_accuracy1 = accuracy_score(y_test, y_test_hat1)*100\n",
        "test_auc_roc1 = roc_auc_score(y_test, y_test_hat_probs1)*100\n",
        "test_precision1 = precision_score(y_test, y_test_hat1)*100\n",
        "test_recall1 = recall_score(y_test, y_test_hat1)*100\n",
        "\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_test, y_test_hat1))\n",
        "\n",
        "print('Testing Accuracy: %.4f %%' % test_accuracy1)\n",
        "print('Testing AUC: %.4f %%' % test_auc_roc1)\n",
        "print('Testing Precision: %.4f %%' % test_precision1)\n",
        "print('Testing Recall: %.4f %%' % test_recall1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cniuSet4S5zx",
        "outputId": "927155ae-1090-4a5d-c305-87b553d97412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0   0.961806  0.993722  0.977503      1115\n",
            "         1.0   0.774194  0.352941  0.484848        68\n",
            "\n",
            "    accuracy                       0.956889      1183\n",
            "   macro avg   0.868000  0.673332  0.731176      1183\n",
            "weighted avg   0.951021  0.956889  0.949185      1183\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print classification report\n",
        "print(classification_report(y_test, y_test_hat1, digits=6))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "#tuning, one_tune_iteration, tune_grid\n",
        "#14-fold cv\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Use grid search to tune the parameters:\n",
        "\n",
        "    parametersGrid = {\"max_iter\": [2:151], \n",
        "                      \"alpha\": (1)), \n",
        "                      \"l1_ratio\": np.arange(0.0)} \n",
        "\n",
        "\n",
        "    eNet = ElasticNet()\n",
        "    grid = GridSearchCV(eNet, parametersGrid, scoring='accuracy', cv=14)\n",
        "    grid.fit(X_train, Y_train)\n",
        "  "
      ],
      "metadata": {
        "id": "GK5Wrs3svosA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o94Ljm0GHQSV"
      },
      "source": [
        "## Model 2: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5p4QHChIy9H",
        "outputId": "ff29663e-84de-4d2a-b54a-546653df4b79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=2000)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#Create a Gaussian Classifier\n",
        "model_rf = RandomForestClassifier(n_estimators=2000)\n",
        "\n",
        "#Train the model using the training sets\n",
        "model_rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating training score"
      ],
      "metadata": {
        "id": "k2guRTi8tyTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_hat_rf = model_rf.predict(X_train)\n",
        "y_train_hat_probs_rf = model_rf.predict_proba(X_train)[:,1]\n",
        "\n",
        "train_accuracy_rf = accuracy_score(y_train, y_train_hat_rf)*100\n",
        "train_auc_roc_rf = roc_auc_score(y_train, y_train_hat_probs_rf)*100\n",
        "train_precision_rf = precision_score(y_train, y_train_hat_rf)*100\n",
        "train_recall_rf = recall_score(y_train, y_train_hat_rf)*100\n",
        "\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_train, y_train_hat_rf))\n",
        "\n",
        "print('Training Accuracy: %.4f %%' % train_accuracy_rf)\n",
        "print('Training AUC: %.4f %%' % train_auc_roc_rf)\n",
        "print('Training Precision: %.4f %%' % train_precision_rf)\n",
        "print('Training Recall: %.4f %%' % train_recall_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j27JXDHrtxL-",
        "outputId": "99535ba8-a2c6-4957-e970-d23d22c0a4a8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[7698    0]\n",
            " [   0  323]]\n",
            "Training Accuracy: 100.0000 %\n",
            "Training AUC: 100.0000 %\n",
            "Training Precision: 100.0000 %\n",
            "Training Recall: 100.0000 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating testing score"
      ],
      "metadata": {
        "id": "JgKnmFL9vCPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_hat_rf = model_rf.predict(X_test)\n",
        "y_test_hat_probs_rf = model_rf.predict_proba(X_test)[:,1]\n",
        "\n",
        "test_accuracy_rf = accuracy_score(y_test, y_test_hat_rf)*100\n",
        "test_auc_roc_rf = roc_auc_score(y_test, y_test_hat_probs_rf)*100\n",
        "test_precision_rf = precision_score(y_test, y_test_hat_rf)*100\n",
        "test_recall_rf = recall_score(y_test, y_test_hat_rf)*100\n",
        "\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_test, y_test_hat_rf))\n",
        "\n",
        "print('testing Accuracy: %.4f %%' % test_accuracy_rf)\n",
        "print('testing AUC: %.4f %%' % test_auc_roc_rf)\n",
        "print('testing Precision: %.4f %%' % test_precision_rf)\n",
        "print('testing Recall: %.4f %%' % train_recall_rf)"
      ],
      "metadata": {
        "id": "21XVCBIPvD2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e553c0-49b0-4919-86c7-b90e7106e42a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[1115    0]\n",
            " [   0   68]]\n",
            "testing Accuracy: 100.0000 %\n",
            "testing AUC: 100.0000 %\n",
            "testing Precision: 100.0000 %\n",
            "testing Recall: 100.0000 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6q7IjVND7Gh"
      },
      "source": [
        "Hyperparameter Tuning Grid Search Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAUINrHaD8gG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27602814-abc2-4be6-d83c-9761d639eabc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2, estimator=RandomForestClassifier(), n_jobs=-1,\n",
              "             param_grid={'bootstrap': [True], 'max_depth': [1, 8],\n",
              "                         'max_features': [5, 8], 'min_samples_leaf': [0.5, 1],\n",
              "                         'n_estimators': [20, 30]},\n",
              "             return_train_score=True, scoring='accuracy', verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "param_grid = {'bootstrap': [True],\n",
        "     'max_depth': [1, 20],\n",
        "     'max_features': [5, 140],\n",
        "     #'min_samples_leaf': [3, 5],\n",
        "     'min_samples_leaf': [0.5, 1],\n",
        "     'n_estimators': [500, 3099] #Is it looking only at 500 and 3099 or everything inbetween???\n",
        "    }\n",
        "     \n",
        "forest_clf = RandomForestClassifier()\n",
        "\n",
        "forest_grid_search = GridSearchCV(forest_clf, param_grid, cv=14,\n",
        "                                  scoring=\"accuracy\",\n",
        "                                  return_train_score=True,\n",
        "                                  verbose=True,\n",
        "                                  n_jobs=-1)\n",
        "\n",
        "forest_grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwKm_CdNHcz7",
        "outputId": "6eeb847f-6477-43b2-9ace-315b9440f2cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': 8,\n",
              " 'max_features': 8,\n",
              " 'min_samples_leaf': 1,\n",
              " 'n_estimators': 20}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "forest_grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xsl1u0uaHgbq"
      },
      "outputs": [],
      "source": [
        "forest_grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19KpH5gNHjpr"
      },
      "outputs": [],
      "source": [
        "forest_grid_search.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict probabilities"
      ],
      "metadata": {
        "id": "G5imuo7LfGv-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qj5A5bH_NsnD"
      },
      "outputs": [],
      "source": [
        "# Predict y values for test data\n",
        "rf_pred=model_rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lrRcf2tN9g8"
      },
      "source": [
        "After training, check the accuracy using actual and predicted values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YPsH56sN-rP"
      },
      "outputs": [],
      "source": [
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, rf_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGsK3O4ci6ha"
      },
      "source": [
        "## Model 3: Gradient Boosted Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L66LHiSolNOP"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "model_xgb = xgb.XGBClassifier(objective ='binary:logistic', n_estimators = 50, learning_rate = 0.25,\n",
        "                              gamma = 0, max_depth = 8, min_child_weight = 2.5, max_delta_step = 5,\n",
        "                              subsample = 0.7, colsample_bytree = 0.65, alpha = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmfkNuBulnNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae9364a6-eca0-40a2-fd77-eb64e9138da5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(alpha=0, colsample_bytree=0.65, learning_rate=0.25,\n",
              "              max_delta_step=5, max_depth=8, min_child_weight=2.5,\n",
              "              n_estimators=50, subsample=0.7)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Fit the model\n",
        "model_xgb.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "T9T9sqFSBRGX"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "xgb_pred = model_xgb.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating training score"
      ],
      "metadata": {
        "id": "CFDHlZgZ4W1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_hat_xgb = model_xgb.predict(X_train)\n",
        "y_train_hat_probs_xgb = model_xgb.predict_proba(X_train)[:,1]\n",
        "\n",
        "train_accuracy_xgb = accuracy_score(y_train, y_train_hat_xgb)*100\n",
        "train_auc_roc_xgb = roc_auc_score(y_train, y_train_hat_probs_xgb)*100\n",
        "train_precision_xgb = precision_score(y_train, y_train_hat_xgb)*100\n",
        "train_recall_xgb = recall_score(y_train, y_train_hat_xgb)*100\n",
        "\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_train, y_train_hat_xgb))\n",
        "\n",
        "print('Training Accuracy: %.4f %%' % train_accuracy_xgb)\n",
        "print('Training AUC: %.4f %%' % train_auc_roc_xgb)\n",
        "print('Training Precision: %.4f %%' % train_precision_xgb)\n",
        "print('Training Recall: %.4f %%' % train_recall_xgb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhEvt8Zn4WN3",
        "outputId": "714c4db7-498b-42a4-c684-76caef071597"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[7698    0]\n",
            " [   9  314]]\n",
            "Training Accuracy: 99.8878 %\n",
            "Training AUC: 99.9990 %\n",
            "Training Precision: 100.0000 %\n",
            "Training Recall: 97.2136 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating testing score"
      ],
      "metadata": {
        "id": "BvImyusB6ETt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_hat_xgb = model_xgb.predict(X_test)\n",
        "y_test_hat_probs_xgb = model_xgb.predict_proba(X_test)[:,1]\n",
        "\n",
        "test_accuracy_xgb = accuracy_score(y_test, y_test_hat_xgb)*100\n",
        "test_auc_roc_xgb = roc_auc_score(y_test, y_test_hat_probs_xgb)*100\n",
        "test_precision_xgb = precision_score(y_test, y_test_hat_xgb)*100\n",
        "test_recall_xgb = recall_score(y_test, y_test_hat_xgb)*100\n",
        "\n",
        "print('Confusion matrix:\\n', confusion_matrix(y_test, y_test_hat_xgb))\n",
        "\n",
        "print('testing Accuracy: %.4f %%' % test_accuracy_xgb)\n",
        "print('testing AUC: %.4f %%' % test_auc_roc_xgb)\n",
        "print('testing Precision: %.4f %%' % test_precision_xgb)\n",
        "print('testing Recall: %.4f %%' % test_recall_xgb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rExEZnF46Dq0",
        "outputId": "a6c24e23-2f58-4d44-b8ef-bbce134fecd4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[1115    0]\n",
            " [   2   66]]\n",
            "testing Accuracy: 99.8309 %\n",
            "testing AUC: 100.0000 %\n",
            "testing Precision: 100.0000 %\n",
            "testing Recall: 97.0588 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n-qah1W_6SCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dcdo2yzBbQP",
        "outputId": "bd545750-0e07-42cf-9d19-7237b0fcaa07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 0.041117\n"
          ]
        }
      ],
      "source": [
        "# Compute the rmse by invoking the mean_sqaured_error function from sklearn's metrics module\n",
        "rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
        "print(\"RMSE: %f\" % (rmse))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [2, 150],\n",
        "    'learning_rate': [0, 1],\n",
        "    'max_depth': [2, 20],\n",
        "    }\n",
        "     \n",
        "xgb_model = xgb.XGBClassifier()\n",
        "\n",
        "xgb_grid_search = GridSearchCV(xgb_model, param_grid, cv=14,\n",
        "                                  scoring=\"accuracy\",\n",
        "                                  return_train_score=True,\n",
        "                                  verbose=True,\n",
        "                                  n_jobs=-1)\n",
        "\n",
        "xgb_grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "1BppkcIb_C1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yRQ0ZCkBIMk"
      },
      "source": [
        "## Ensemble Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate predicted probabilities for each model\n",
        "logit_pred_probabilties = model1.predict_proba(X_train)[:,1]\n",
        "rf_pred_probabilties = model_rf.predict_proba(X_train)[:,1]\n",
        "xgb_pred_probabilties = model_xgb.predict_proba(X_train)[:,1]"
      ],
      "metadata": {
        "id": "gSbzuaJ8tDJ_"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of predicted probabilities (\"risk estimates\") from Logit Model with Elastic Net Regularization\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.suptitle('Predicted probabilities from Logit Model with Elastic Net Regularization', fontsize=15)\n",
        "plt.hist(logit_pred_probabilties[y_train==0], bins=50, label='Negatives')\n",
        "plt.hist(logit_pred_probabilties[y_train==1], bins=50, label='Positives', alpha=0.7, color='r')\n",
        "plt.xlabel('Probability of being Positive Class (y = 1)', fontsize=15)\n",
        "plt.ylabel('Frequency', fontsize=20)\n",
        "plt.legend(fontsize=10)\n",
        "plt.tick_params(axis='both', labelsize=12, pad=5)\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "LYEw2al9tEMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of predicted probabilities (\"risk estimates\") from Random Forest Model\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.suptitle('Predicted probabilities from Random Forest Model', fontsize=15)\n",
        "plt.hist(rf_pred_probabilties[y_train==0], bins=50, label='Negatives')\n",
        "plt.hist(rf_pred_probabilties[y_train==1], bins=50, label='Positives', alpha=0.7, color='r')\n",
        "plt.xlabel('Probability of being Positive Class (y = 1)', fontsize=15)\n",
        "plt.ylabel('Frequency', fontsize=20)\n",
        "plt.legend(fontsize=10)\n",
        "plt.tick_params(axis='both', labelsize=12, pad=5)\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "iP3sEnsrtHY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of predicted probabilities (\"risk estimates\") from Gradient Boosted Forest Model\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.suptitle('Predicted probabilities from Gradient Boosted Forest Model', fontsize=15)\n",
        "plt.hist(xgb_pred_probabilties[y_train==0], bins=50, label='Negatives')\n",
        "plt.hist(xgb_pred_probabilties[y_train==1], bins=50, label='Positives', alpha=0.7, color='r')\n",
        "plt.xlabel('Probability of being Positive Class (y = 1)', fontsize=15)\n",
        "plt.ylabel('Frequency', fontsize=20)\n",
        "plt.legend(fontsize=10)\n",
        "plt.tick_params(axis='both', labelsize=12, pad=5)\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "Ecx1WdHNtJjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble model for predicted probabilities (unweighted average as in the baseline paper)\n",
        "average_pred_probabilities = (logit_pred_probabilties+\n",
        "                              rf_pred_probabilties+\n",
        "                              xgb_pred_probabilties)/3\n",
        "\n",
        "average_pred_probabilities"
      ],
      "metadata": {
        "id": "ElGfxakbtLZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of predicted probabilities (\"risk estimates\") from Ensemble Model\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.suptitle('Predicted probabilities from Ensemble Model', fontsize=15)\n",
        "plt.hist(average_pred_probabilities[y_train==0], bins=50, label='Negatives')\n",
        "plt.hist(average_pred_probabilities[y_train==1], bins=50, label='Positives', alpha=0.7, color='r')\n",
        "plt.xlabel('Probability of being Positive Class (y = 1)', fontsize=15)\n",
        "plt.ylabel('Frequency', fontsize=20)\n",
        "plt.legend(fontsize=10)\n",
        "plt.tick_params(axis='both', labelsize=12, pad=5)\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "PV8ZzRKJtRBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFgH5e4EkicY"
      },
      "outputs": [],
      "source": [
        "# Ensemble for predicted labels (class), i.e. 0 or 1\n",
        "average_pred = (logit_pred+\n",
        "                rf_pred+\n",
        "                XGB_pred)/3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jyrs60i1Es"
      },
      "source": [
        "## Cross-Validation (2x7 k-fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghL8OCShmbL4"
      },
      "outputs": [],
      "source": [
        "cv = RepeatedKFold(n_splits = 7, n_repeats = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bftLDhIai1Es"
      },
      "source": [
        "### Model 0 (Plain Logistic Regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAC-bStxi1Es"
      },
      "outputs": [],
      "source": [
        "model_0_cv_roc_auc = cross_val_score(model0, X_train, y_train, scoring = \"roc_auc\", cv = cv)\n",
        "model_0_cv_precision = cross_val_score(model0, X_train, y_train, scoring = \"recall\", cv = cv)\n",
        "model_0_cv_brier = cross_val_score(model0, X_train, y_train, scoring = \"neg_brier_score\", cv = cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibj7z2gyoayG",
        "outputId": "a281de28-5dee-47c6-bd9d-c7b022737b4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8442572869016508\n",
            "0.22739070389617597\n",
            "-0.039891734126948186\n"
          ]
        }
      ],
      "source": [
        "# print(model_0_cv_roc_auc)\n",
        "print(np.sum(model_0_cv_roc_auc) / len(model_0_cv_roc_auc))\n",
        "# print(model_0_cv_precision)\n",
        "print(np.sum(model_0_cv_precision) / len(model_0_cv_precision))\n",
        "# print(model_0_cv_brier)\n",
        "print(np.sum(model_0_cv_brier) / len(model_0_cv_brier))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kPMGi9GnlKG"
      },
      "source": [
        "### Model 1 (Logistic Regression with Elastic Net Regularization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-X1vxbvmmhq"
      },
      "outputs": [],
      "source": [
        "model_1_cv_accuracy = cross_val_score(model1, X_train, y_train, scoring = \"accuracy\", cv = cv)\n",
        "model_1_cv_roc_auc = cross_val_score(model1, X_train, y_train, scoring = \"roc_auc\", cv = cv)\n",
        "model_1_cv_precision = cross_val_score(model1, X_train, y_train, scoring = \"precision\", cv = cv)\n",
        "model_1_cv_recall = cross_val_score(model1, X_train, y_train, scoring = \"recall\", cv = cv)\n",
        "#model_1_cv_brier = cross_val_score(model1, X_train, y_train, scoring = \"neg_brier_score\", cv = cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vCvDLj6peer"
      },
      "outputs": [],
      "source": [
        "print(np.sum(model_1_cv_accuracy) / len(model_1_cv_accuracy))\n",
        "print(np.sum(model_1_cv_roc_auc) / len(model_1_cv_roc_auc))\n",
        "print(np.sum(model_1_cv_precision) / len(model_1_cv_precision))\n",
        "print(np.sum(model_1_cv_recall) / len(model_1_cv_recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyL8TSvZnpfc"
      },
      "source": [
        "### Model 2 (Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61jqJlw0no7g"
      },
      "outputs": [],
      "source": [
        "model_rf_cv_accuracy = cross_val_score(model_rf, X_train, y_train, scoring = \"accuracy\", cv = cv)\n",
        "model_rf_cv_roc_auc = cross_val_score(model_rf, X_train, y_train, scoring = \"roc_auc\", cv = cv)\n",
        "model_rf_cv_precision = cross_val_score(model_rf, X_train, y_train, scoring = \"precision\", cv = cv)\n",
        "model_rf_cv_recall = cross_val_score(model_rf, X_train, y_train, scoring = \"recall\", cv = cv)\n",
        "#model_rf_cv_brier = cross_val_score(model_rf, X_train, y_train, scoring = \"neg_brier_score\", cv = cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcLqQlnRpg14"
      },
      "outputs": [],
      "source": [
        "print(np.sum(model_rf_cv_accuracy) / len(model_rf_cv_accuracy))\n",
        "print(np.sum(model_rf_cv_roc_auc) / len(model_rf_cv_roc_auc))\n",
        "print(np.sum(model_rf_cv_precision) / len(model_rf_cv_precision))\n",
        "print(np.sum(model_rf_cv_recall) / len(model_rf_cv_recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAy-K0Oso_Bo"
      },
      "source": [
        "### Model 3 (Gradient Boosted Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ArYzVSApEXC"
      },
      "outputs": [],
      "source": [
        "model_xgb_cv_accuracy = cross_val_score(model_xgb, X_train, y_train, scoring = \"accuracy\", cv = cv)\n",
        "model_xgb_cv_roc_auc = cross_val_score(model_xgb, X_train, y_train, scoring = \"roc_auc\", cv = cv)\n",
        "model_xgb_cv_precision = cross_val_score(model_xgb, X_train, y_train, scoring = \"precision\", cv = cv)\n",
        "model_xgb_cv_recall = cross_val_score(model_xgb, X_train, y_train, scoring = \"recall\", cv = cv)\n",
        "#model_xgb_cv_brier = cross_val_score(model_xgb, X_train, y_train, scoring = \"neg_brier_score\", cv = cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orKfh4eNpjfQ"
      },
      "outputs": [],
      "source": [
        "print(np.sum(model_xgb_cv_accuracy) / len(model_xgb_cv_accuracy))\n",
        "print(np.sum(model_xgb_cv_roc_auc) / len(model_xgb_cv_roc_auc))\n",
        "print(np.sum(model_xgb_cv_precision) / len(model_xgb_cv_precision))\n",
        "print(np.sum(model_xgb_cv_recall) / len(model_xgb_cv_recall))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "baseline_models.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}